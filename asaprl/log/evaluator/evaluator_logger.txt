[2023-03-07 06:50:28,181][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 34.599998474121094, current episode: 1
[2023-03-07 06:51:48,747][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 33.900001525878906, current episode: 2
[2023-03-07 06:53:59,907][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 17.299999237060547, current episode: 1
[2025-11-27 14:55:20,158][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 62.099998474121094, current episode: 1
[2025-11-27 14:55:46,430][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 67.69999694824219, current episode: 2
[2025-11-27 14:56:18,966][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 61.599998474121094, current episode: 3
[2025-11-27 14:56:49,098][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 69.0, current episode: 4
[2025-11-27 14:57:23,115][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 62.0, current episode: 5
[2025-11-27 14:57:48,604][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 65.19999694824219, current episode: 6
[2025-11-27 14:58:27,476][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 61.5, current episode: 7
[2025-11-27 14:59:03,165][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 63.900001525878906, current episode: 8
[2025-11-27 14:59:44,378][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 72.5999984741211, current episode: 9
[2025-11-27 15:00:17,067][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 69.0, current episode: 10
[2025-11-27 15:00:51,635][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 64.0999984741211, current episode: 11
[2025-11-27 15:01:27,501][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 71.80000305175781, current episode: 12
[2025-11-27 15:02:05,390][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 67.5, current episode: 13
[2025-11-27 15:02:45,421][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 64.0999984741211, current episode: 14
[2025-11-27 15:03:19,013][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 66.69999694824219, current episode: 15
[2025-11-27 15:03:53,808][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 67.4000015258789, current episode: 16
[2025-11-27 15:04:23,078][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 44.0, current episode: 17
[2025-11-27 15:04:56,663][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 64.0, current episode: 18
[2025-11-27 15:05:37,243][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 61.099998474121094, current episode: 19
[2025-11-27 15:06:17,959][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 71.5999984741211, current episode: 20
[2025-11-27 15:06:17,964][evaluator_utils.py][line: 550][    INFO] 
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Name  | train_iter | ckpt_name            | episode_count | envstep_count  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min |
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Value | -1.000000  | iteration_-1.pth.tar | 20.000000     | 1889080.000000 | 94454.000000            | 690.003686    | 2737.782476         | 0.028985             | 64.844999   | 5.926928   | 72.599998  | 44.000000  |
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
[2025-11-27 15:12:17,514][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 61.70000076293945, current episode: 1
[2025-11-27 15:12:51,598][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 56.20000076293945, current episode: 2
[2025-11-27 15:13:28,068][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 65.19999694824219, current episode: 3
[2025-11-27 15:14:03,735][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 60.099998474121094, current episode: 4
[2025-11-27 15:14:45,513][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 59.29999923706055, current episode: 5
[2025-11-27 15:15:26,523][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 67.4000015258789, current episode: 6
[2025-11-27 15:15:58,136][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 62.099998474121094, current episode: 7
[2025-11-27 15:16:31,723][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 64.19999694824219, current episode: 8
[2025-11-27 15:17:08,776][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 59.900001525878906, current episode: 9
[2025-11-27 15:17:41,916][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 62.29999923706055, current episode: 10
[2025-11-27 15:18:10,770][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 60.79999923706055, current episode: 11
[2025-11-27 15:18:53,393][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 71.4000015258789, current episode: 12
[2025-11-27 15:19:34,297][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 70.5, current episode: 13
[2025-11-27 15:20:16,234][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 70.69999694824219, current episode: 14
[2025-11-27 15:20:56,930][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 63.900001525878906, current episode: 15
[2025-11-27 15:21:35,617][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 70.0, current episode: 16
[2025-11-27 15:22:08,570][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 69.9000015258789, current episode: 17
[2025-11-27 15:22:41,522][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 67.0999984741211, current episode: 18
[2025-11-27 15:23:14,718][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 68.9000015258789, current episode: 19
[2025-11-27 15:23:46,303][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 68.9000015258789, current episode: 20
[2025-11-27 15:23:46,310][evaluator_utils.py][line: 550][    INFO] 
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Name  | train_iter | ckpt_name            | episode_count | envstep_count  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min |
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Value | -1.000000  | iteration_-1.pth.tar | 20.000000     | 2028280.000000 | 101414.000000           | 723.905691    | 2801.856686         | 0.027628             | 65.025000   | 4.468543   | 71.400002  | 56.200001  |
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
[2025-12-05 10:39:42,380][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 64.30000305175781, current episode: 1
[2025-12-05 10:40:21,162][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 72.5, current episode: 2
[2025-12-05 10:41:07,197][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 66.5999984741211, current episode: 3
[2025-12-05 10:41:44,248][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 58.900001525878906, current episode: 4
[2025-12-05 10:42:10,842][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 68.0999984741211, current episode: 5
[2025-12-05 10:42:49,500][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 63.900001525878906, current episode: 6
[2025-12-05 10:43:29,391][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 51.400001525878906, current episode: 7
[2025-12-05 10:43:57,826][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 69.4000015258789, current episode: 8
[2025-12-05 10:44:31,883][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 68.0, current episode: 9
[2025-12-05 10:45:12,082][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 59.5, current episode: 10
[2025-12-05 10:45:50,790][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 63.70000076293945, current episode: 11
[2025-12-05 10:46:27,924][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 68.0, current episode: 12
[2025-12-05 10:47:02,093][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 68.19999694824219, current episode: 13
[2025-12-05 10:47:44,807][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 67.5, current episode: 14
[2025-12-05 10:48:21,802][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 63.20000076293945, current episode: 15
[2025-12-05 10:48:52,453][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 62.5, current episode: 16
[2025-12-05 10:49:30,592][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 66.69999694824219, current episode: 17
[2025-12-05 10:50:08,613][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 64.5999984741211, current episode: 18
[2025-12-05 10:50:51,946][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 59.0, current episode: 19
[2025-12-05 10:51:23,094][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 65.5999984741211, current episode: 20
[2025-12-05 10:51:23,103][evaluator_utils.py][line: 550][    INFO] 
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Name  | train_iter | ckpt_name            | episode_count | envstep_count  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min |
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Value | -1.000000  | iteration_-1.pth.tar | 20.000000     | 2105410.000000 | 105270.500000           | 739.672562    | 2846.408139         | 0.027039             | 64.580000   | 4.601369   | 72.500000  | 51.400002  |
+-------+------------+----------------------+---------------+----------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
[2025-12-11 17:29:10,742][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 30.100000381469727, current episode: 1
[2025-12-11 17:29:32,870][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 35.599998474121094, current episode: 2
[2025-12-11 17:29:56,887][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 40.0, current episode: 3
[2025-12-11 17:30:15,211][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 25.700000762939453, current episode: 4
[2025-12-11 17:30:30,023][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 31.200000762939453, current episode: 5
[2025-12-11 17:30:47,943][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 31.0, current episode: 6
[2025-12-11 17:31:00,597][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 23.0, current episode: 7
[2025-12-11 17:31:08,374][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.399999976158142, current episode: 8
[2025-12-11 17:31:25,446][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 34.400001525878906, current episode: 9
[2025-12-11 17:31:44,729][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 27.700000762939453, current episode: 10
[2025-12-11 17:32:12,125][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 36.79999923706055, current episode: 11
[2025-12-11 17:32:27,309][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 30.799999237060547, current episode: 12
[2025-12-11 17:32:44,619][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 26.899999618530273, current episode: 13
[2025-12-11 17:33:05,074][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 35.0, current episode: 14
[2025-12-11 17:33:27,876][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 38.0, current episode: 15
[2025-12-11 17:33:43,140][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 30.899999618530273, current episode: 16
[2025-12-11 17:33:59,671][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 34.099998474121094, current episode: 17
[2025-12-11 17:34:12,153][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 23.200000762939453, current episode: 18
[2025-12-11 17:34:29,327][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 31.899999618530273, current episode: 19
[2025-12-11 17:34:41,623][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 28.0, current episode: 20
[2025-12-11 17:34:41,625][evaluator_utils.py][line: 550][    INFO] 
+-------+------------+----------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Name  | train_iter | ckpt_name            | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min |
+-------+------------+----------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Value | -1.000000  | iteration_-1.pth.tar | 20.000000     | 405720.000000 | 20286.000000            | 345.738091    | 1173.489444         | 0.057847             | 29.785000   | 7.937082   | 40.000000  | 1.400000   |
+-------+------------+----------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
[2025-12-11 18:24:41,057][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 45.099998474121094, current episode: 1
[2025-12-11 18:24:48,505][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: -0.10000000149011612, current episode: 2
[2025-12-11 18:25:26,566][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 51.5, current episode: 3
[2025-12-11 18:26:36,672][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 76.9000015258789, current episode: 4
[2025-12-11 18:27:08,851][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 44.0, current episode: 5
[2025-12-11 18:27:37,868][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 48.0, current episode: 6
[2025-12-11 18:27:47,139][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: -0.20000000298023224, current episode: 7
[2025-12-11 18:28:26,829][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 46.900001525878906, current episode: 8
[2025-12-11 18:28:59,557][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 47.29999923706055, current episode: 9
[2025-12-11 18:29:37,402][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 35.70000076293945, current episode: 10
[2025-12-11 18:29:46,088][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 3.0999999046325684, current episode: 11
[2025-12-11 18:29:56,469][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 0.800000011920929, current episode: 12
[2025-12-11 18:30:40,289][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 49.599998474121094, current episode: 13
[2025-12-11 18:31:35,014][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 56.20000076293945, current episode: 14
[2025-12-11 18:32:08,609][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 49.29999923706055, current episode: 15
[2025-12-11 18:32:40,879][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 35.20000076293945, current episode: 16
[2025-12-11 18:32:48,409][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.7999999523162842, current episode: 17
[2025-12-11 18:32:58,522][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 18
[2025-12-11 18:33:09,942][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 1.0, current episode: 19
[2025-12-11 18:33:18,417][evaluator_utils.py][line: 524][    INFO] [EVALUATOR]env 0 finish episode, final reward: 2.0999999046325684, current episode: 20
[2025-12-11 18:33:18,418][evaluator_utils.py][line: 550][    INFO] 
+-------+------------+----------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Name  | train_iter | ckpt_name            | episode_count | envstep_count | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode | reward_mean | reward_std | reward_max | reward_min |
+-------+------------+----------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
| Value | -1.000000  | iteration_-1.pth.tar | 20.000000     | 771160.000000 | 38558.000000            | 544.998785    | 1414.975632         | 0.036697             | 29.760000   | 24.643648  | 76.900002  | -0.200000  |
+-------+------------+----------------------+---------------+---------------+-------------------------+---------------+---------------------+----------------------+-------------+------------+------------+------------+
